{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses\n",
    "\n",
    "Losses in vschaos are implemented using the `vschaos.criterions.Criterion` object, a sub-class of the pytorch loss objects providing addditional features a dynamical naming, loss algebra, and tracking. Alternative losses can be used to defined evolved variational auto-encoding modules such as for example beta-VAE, Wasserstein auto-encoders, and many more. \n",
    "\n",
    "This object outputs two arguments : the overall loss, and a tuple containing the individual losses of the criterion, if it is composed of several sub-losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse_loss_0': tensor(19.9847), 'mse_loss_1': tensor(19.5847)}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import vschaos.criterions as crit\n",
    "import vschaos.distributions as dist\n",
    "\n",
    "# crit.M\n",
    "l2 = crit.MSE()\n",
    "\n",
    "out_params = [dist.Normal(torch.zeros(64, 10).normal_(), torch.zeros(64, 10).normal_()),\n",
    "              dist.Normal(torch.zeros(64, 10).normal_(), torch.zeros(64, 10).normal_())]\n",
    "target = [torch.zeros(64, 10).normal_(), torch.zeros(64, 10).normal_()]\n",
    "\n",
    "loss_out, losses = l2(out_params, target)\n",
    "\n",
    "# every Criterion should implement the Criterion.get_named_losses(), that returns the named losses from\n",
    "#   individual tuples\n",
    "named_losses = l2.get_named_losses(losses)\n",
    "print(named_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Criterion` objects also support basic algebras (+, -, /, \\*, \\*\\*). In that case, the individual losses returned by the second argument represent the individual values, unaffected by the loss intern calculus. Moreover, loss tracking can be achieved directly in the corresponding criterion using the write function. Intern time tracking is also done, allowing to plot index losses in the time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(195.9405) {'l1_loss_0': tensor(1.1102), 'l1_loss_1': tensor(1.1275), 'mse_loss_0': tensor(9.9923), 'mse_loss_1': tensor(9.7923)}\n",
      "{'train': {'l1_loss_0': {'values': array([1.1102383], dtype=float32), 'time': [1.958661]}, 'l1_loss_1': {'values': array([1.127469], dtype=float32), 'time': [1.958661]}, 'mse_loss_0': {'values': array([9.992333], dtype=float32), 'time': [1.9588670000000001]}, 'mse_loss_1': {'values': array([9.792345], dtype=float32), 'time': [1.9588670000000001]}}}\n"
     ]
    }
   ],
   "source": [
    "l1 = crit.L1()\n",
    "\n",
    "reconstruction_loss = 0.1*l1 + 0.5*l2**2\n",
    "loss_out, losses = reconstruction_loss(out_params, target)\n",
    "print(loss_out, reconstruction_loss.get_named_losses(losses))\n",
    "\n",
    "# write losses in the loss history\n",
    "reconstruction_loss.write(\"train\", losses)\n",
    "print(reconstruction_loss.loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library also defines higher-order criterions, such as the `ELBO`criterion that parses the output of the VAE to corresponding losses. Reconstruction and regularization are by default respectively `LogDensity` and `KLD`, but can be changed when creating the ELBO object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'l1_loss_0': 439.4884338378906, 'mse_loss_0': 591.8547973632812, 'log_density_0': 1430.23779296875, 'mmd_0': 90.74755859375, 'mmd_1': 41.56732177734375}\n"
     ]
    }
   ],
   "source": [
    "from vschaos import vaes\n",
    "import torch\n",
    "import vschaos.criterions as crit\n",
    "import vschaos.distributions as dist\n",
    "\n",
    "reconstruction_loss = 0.3*crit.L1() + crit.MSE() + 0.4*crit.LogDensity()\n",
    "reconstruction_loss = reconstruction_loss\n",
    "# here are some specific losses for spectrums (set transform to 'stft' if applied on raw signals)\n",
    "spectral_loss = crit.SpectralLoss(losses=['spec_conv', 'log_isd', 'log_diff', 'l2_mag'],\n",
    "                                  weights=[1.0, 1.0, 1.0, 1.0], transform=None)\n",
    "regularization_loss = crit.MMD()\n",
    "\n",
    "elbo_loss = crit.ELBO(reconstruction_loss=reconstruction_loss, regularization_loss=regularization_loss)\n",
    "\n",
    "input_params = {'dim':512, 'dist':dist.Normal}\n",
    "hidden_prarams = [{'dim':200, 'nlayers':3, 'nn_lin':'Sigmoid'}, {'dim':100, 'nlayers':3, 'nn_lin':'Sigmoid'}]\n",
    "latent_params = [{'dim':16, 'dist':dist.Normal}, {'dim':8, 'dist':dist.Normal}]\n",
    "\n",
    "vae = vaes.VanillaVAE(input_params, latent_params, hidden_params=hidden_prarams)\n",
    "\n",
    "x = torch.zeros(64, 512).normal_()\n",
    "out_vae = vae(x)\n",
    "loss_out, losses_out = elbo_loss(model=vae, target=x, out=out_vae)\n",
    "# get named losses return individual losses *without weighting*, in order to monitor them properly\n",
    "print(elbo_loss.get_named_losses(losses_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
