{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAEs\n",
    "\n",
    "## Defining a VAE model\n",
    "\n",
    "`vschaos` allow to easily define signle-layered or multi-layered variational auto-encoding models by only specifying their *signature*, creating automatically the modules described in the previous section. Each model is defined by a set of three dictionaries defining respectively \n",
    "* the *input parameters*, that can be accessed with `vae.input_params`\n",
    "* the *latent parameters*, that can be accessed with `vae.latent_params`\n",
    "* the *hidden parameters*, that can be accessed with `vae.hidden_params`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vschaos\n",
    "import vschaos.distributions as dist\n",
    "import vschaos.vaes as vaes\n",
    "from vschaos.modules import *\n",
    "from vschaos.data import dataset_from_torchvision, Flatten\n",
    "\n",
    "from torchvision.transforms import Lambda, ToTensor\n",
    "from vschaos.vaes import VanillaVAE\n",
    "\n",
    "# import MNIST\n",
    "transforms = [Lambda(lambda x: x / 255. + 0.01*torch.randn_like(x.float())), Flatten(-2)]\n",
    "dataset = dataset_from_torchvision('MNIST', transforms=transforms)\n",
    "\n",
    "# make VAE parameters\n",
    "input_params = {'dim':784, 'dist': dist.Normal}\n",
    "class_params = {'dim':10, 'dist':dist.Categorical}\n",
    "# different architectures for encoders and decoders can be specified using \"encoder\"\n",
    "#   and \"decoder\" keywords\n",
    "encoder_params = {'dim':800, 'nlayers':2}\n",
    "decoder_params = {'dim':800, 'nlayers':3, 'normalization':None}\n",
    "hidden_params = {'encoder':encoder_params, 'decoder':decoder_params}\n",
    "\n",
    "latent_params = {'dim':8, \"dist\":dist.Normal}\n",
    "\n",
    "# as simple as that!\n",
    "vae = vaes.VanillaVAE(input_params, latent_params, hidden_params=hidden_params)\n",
    "# if cuda\n",
    "cuda = -1\n",
    "device = torch.device(cuda) if 0 else -1\n",
    "if cuda >= 0:\n",
    "    vae = vae.cuda(cuda)\n",
    "\n",
    "with torch.cuda.device(device):\n",
    "    x, y = dataset[:64]\n",
    "    out = vae(x, y=y)\n",
    "print(\"latent parameters : \", out['z_params_enc'][0])\n",
    "print(\"latent samples : \", out['z_enc'][0].shape)\n",
    "print(\"data parameters : \", out['x_params'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each VAE of `vschaos` package derive from the abstract class `vschaos.vaes.AbstractVAE` , defining several high-level function such as model saving / loading, or registering a set of projected points using invertible dimensionality reduction methods, called *manifolds*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the vae can be saved using the `save method`, along with arbitrary data given as keywords\n",
    "vae.save('test_save.pth', transforms=transforms)\n",
    "\n",
    "# the load function also save a patch of the class, such that the object\n",
    "#   can be initialized again\n",
    "loaded_data = torch.load('test_save.pth')\n",
    "vae = loaded_data['class'].load(loaded_data)\n",
    "transforms = loaded_data['transforms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a VAE model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a VAE implies first initializing its optimizer, then choosing an accurate loss, and then repeat the training routine for a given number of epoch. While custom training routines can be defined, a high level object called `vschaos.train.SimpleTrainer` can be used to automatically perform casual tracking operations such as plotting, generating, early stopping, and model saving.\n",
    "\n",
    "These three steps are proceeded as follows : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vschaos.criterions import ELBO\n",
    "from vschaos.monitor.visualize_dimred import PCA\n",
    "from vschaos.train import SimpleTrainer, train_model\n",
    "\n",
    "# initializing optimizer\n",
    "optim_params = {'optimizer':'Adam', 'optimArgs':{'lr':1e-3}, 'scheduler':'ReduceLROnPlateau'}\n",
    "vae.init_optimizer(optim_params)\n",
    "\n",
    "# defining a loss (see next notebook)\n",
    "loss = ELBO(beta=4.0, warmup=20)\n",
    "\n",
    "# The Trainer object performs training, monitoring, and automating saving during the training process.\n",
    "dataset = dataset.retrieve(np.random.permutation(len(dataset.data))[:1000])\n",
    "plots = {}\n",
    "plots['reconstructions'] = {'preprocess': False, \"transforms\":transforms, \"n_points\":15, 'plot_multihead':True, 'label':['class']}\n",
    "plots['latent_space'] = {'preprocess':False, 'transformation':PCA, 'tasks':'class', 'balanced':True, 'n_points':3000, 'label':['class'], 'batch_size':512}\n",
    "\n",
    "trainer = SimpleTrainer(vae, dataset, loss, tasks=[\"class\"], plots=plots, use_tensorboard=\"runs/\")\n",
    "device = torch.device(cuda) if cuda >= 0 else -1\n",
    "\n",
    "train_options = {'epochs':100, 'save_epochs':20, 'results_folder':'tutorial_3',  'batch_size':64}\n",
    "with torch.cuda.device(device):\n",
    "    train_model(trainer, train_options, save_with={'transforms':dataset.classes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
