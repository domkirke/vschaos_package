{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA IMPORT\n",
    "\n",
    "Data import and processing are crucial step in both learning / using machine learning models. Hence, `vschaos` provide high-level methods for easy data loading / processing that can be used both for general data, and specific methods for audio (transforms, inversion, time conditioning). \n",
    "\n",
    "## Dataset import in `vschaos` \n",
    "\n",
    "Data import is handled by the :py:class:`Dataset` object, that implements most data / metadata operations. \n",
    "Datasets in `vschaos` imply a specific architecture, that can be split across different folders. This \n",
    "architecture is based on three separate folders, that are usually included in a root directory :\n",
    "* *data/*, containing all the raw data (as wav or mp3 for audio) \n",
    "* *analysis/*, containing different transforms with various transformation parameters* \n",
    "* *metadata/*, containing the metadata of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` object has to be initialised using a dictionary, specifying the properties of the import. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from vschaos.data import Dataset\n",
    "# The ./dataset folder contains a dummy dataset\n",
    "data_prefix = \"dataset\"\n",
    "# Creating object \n",
    "# if data / metadata /analysis are not contained within a single location, \n",
    "#   locations can be specified with data_directory / metadata_directory / analysis_directory \n",
    "dataset = Dataset(data_prefix)\n",
    "print(f\"{dataset}, tasks : {dataset.tasks}\")\n",
    "print('files : ', dataset.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generic class `Dataset` does not have an import function by default. A callback function has to be specified to import data using the `Dataset.import_data` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.data import Dataset\n",
    "import torchaudio\n",
    "\n",
    "def audio_callback(self, file, **kwargs):\n",
    "    return torchaudio.load(file)[0], None\n",
    "\n",
    "data_prefix = \"dataset\"\n",
    "dataset = Dataset(data_prefix, import_callback=audio_callback)\n",
    "dataset.import_data()\n",
    "data, metadata = dataset[:]\n",
    "print(\"data : \", data.shape)\n",
    "print(\"metadata : \", metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful : the Dataset object is able to deal with data of variable length, as it does here with audio files of different duration. However, depending of the fianl size, the collating operation can be expensive. It is thus strongly advised to fix the data size (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dataset.data:\n",
    "    print(d.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw inputs have generally to be adapted to a model's input in order to be suitable for learning. This is done with `Transform` objects, contained in the `data_transforms.py` module. A sequence of transformations can be used using the `ComposeTransform` function. This can be used for cropping, (un)squeezing, or transforming the data in several ways before loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.data import Dataset\n",
    "from vschaos.data.data_transforms import Squeeze, Sequence, ComposeTransform\n",
    "import torchaudio\n",
    "\n",
    "def audio_callback(self, file, **kwargs):\n",
    "    return torchaudio.load(file)[0], {}\n",
    "\n",
    "data_prefix = \"dataset\"\n",
    "dataset = Dataset(data_prefix, import_callback=audio_callback)\n",
    "dataset.import_data()\n",
    "\n",
    "#Sequence transform takes a sub-sequence of input data among given axis\n",
    "transforms = ComposeTransform([Squeeze(0), Sequence(512, dim=0, random_start=True)])\n",
    "\n",
    "x, y = dataset[0]\n",
    "out = transforms(x)\n",
    "x_inv = transforms.invert(out)\n",
    "\n",
    "print(x.shape, '->', out.shape, '->', x_inv.shape)\n",
    "\n",
    "# Transforms can be directly embedded in the Dataset object, such that it is applied when using __getitem__ method\n",
    "dataset = Dataset(data_prefix, import_callback=audio_callback, transforms=transforms)\n",
    "dataset.import_data(scale=False) # Here we do not scale the transforms (further information below)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(4,4)\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax[i, j].plot(dataset[0][0].numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some transforms, such as normalization procedures, need first to be *scaled* to a given dataset. Hence, each embedded transform are scaled to a given amount of data that can be specified using the `scale` keyword. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.data import Dataset, Sequence, Normalize, ComposeTransform, Unsqueeze\n",
    "import torchaudio\n",
    "\n",
    "def audio_callback(self, file, **kwargs):\n",
    "    return torchaudio.load(file)[0], None\n",
    "\n",
    "data_prefix = \"dataset\"\n",
    "dataset = Dataset(data_prefix, transforms=[Normalize(mode=\"gaussian\", scale=\"bipolar\")], import_callback=audio_callback)\n",
    "# scale can be False, True (normalize on all the dataset), or an int (randomly picking files)\n",
    "dataset.import_data(scale=2)\n",
    "\n",
    "x, y = dataset[:]\n",
    "print(x.min(), x.max(), x.mean(), x.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Dataset` object can be directly indexed to obtain a tuple `(x, y)` containing the data and the metadata of the target slice. Sub-datasets can be obtained by using the `retrieve` method, that can be called whether with a set of indicies, or with a partition name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.data import Dataset\n",
    "from vschaos.data.data_transforms import Binary\n",
    "from vschaos.utils.dataloader import DataLoader\n",
    "import torchaudio\n",
    "\n",
    "def audio_callback(self, file, **kwargs):\n",
    "    return torchaudio.load(file)[0][0, :2000], None\n",
    "\n",
    "data_prefix = \"dataset\"\n",
    "dataset = Dataset(data_prefix, transforms=[Binary()], import_callback=audio_callback)\n",
    "dataset.import_data(scale=True)\n",
    "dataset.apply_transforms() # the apply_transform method overwrites the data and flushes the Dataset's transforms\n",
    "\n",
    "dataset.construct_partition(['train', 'test'], [0.8, 0.2])\n",
    "print(dataset.partitions['train'])\n",
    "\n",
    "\n",
    "train_dataset = dataset.retrieve('train')\n",
    "# we have to set the loaded metadata with the `drop_tasks` method\n",
    "data_loader = DataLoader(train_dataset, 64, tasks=dataset.tasks)\n",
    "x, y = next(data_loader.__iter__())\n",
    "print(x.shape, y.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving / loading transforms\n",
    "\n",
    "Transforms can also be saved in the dataset analysis path using the `Dataset.write_transform` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, torchaudio\n",
    "from vschaos.data import Dataset, DatasetAudio\n",
    "from vschaos.data.data_transforms import Mono, STFT, Squeeze\n",
    "from vschaos.utils.dataloader import DataLoader\n",
    "\n",
    "def audio_callback(self, file, **kwargs):\n",
    "    return torchaudio.load(file)[0][:, :2000], {}\n",
    "\n",
    "data_prefix = \"dataset\"\n",
    "dataset = Dataset(data_prefix, transforms=[Mono(), Squeeze(0)], import_callback=audio_callback)\n",
    "dataset.import_data()\n",
    "# if the transforms keyword is None, write_transforms take the dataset's transforms\n",
    "dataset.write_transform('stft-1024', transforms=[STFT(1024)], scale=True)\n",
    "print(\"content of analysis dir : \", os.listdir(f'{data_prefix}/analysis'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforms are saved as `numpy.memmap`, hence allowing asynchronous import using the `OfflineDataList` object. If the `offline` keyword is `True`, `Dataset.data` is then a collection of callback called dynamically with the `__getitem`. As `numpy.memmap` arrays, selectors can be specified in order to load just a part of the file, allowing light import when training on large files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.data import Dataset, SequencePick\n",
    "\n",
    "dataset = Dataset(data_prefix)\n",
    "dataset, transforms = dataset.load_transform('stft-1024', offline=False)\n",
    "print('-- regular import')\n",
    "print(\"type of dataset.data : \", type(dataset.data))\n",
    "print(dataset[0][0].shape)\n",
    "\n",
    "dataset = Dataset(data_prefix)\n",
    "dataset, transforms = dataset.load_transform('stft-1024', offline=True)\n",
    "print('-- asynchronous import')\n",
    "print(\"type of dataset.data : \", type(dataset.data))\n",
    "print(dataset[0][0].shape)\n",
    "\n",
    "dataset.load_transform('stft-1024', offline=True,\n",
    "                       selector=SequencePick,\n",
    "                       selector_args={'axis':0, 'sequence_length':60, 'random_idx':False})\n",
    "print('-- asynchronous import')\n",
    "print(\"type of dataset.data : \", type(dataset.data))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(2,2)\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        ax[i, j].imshow(dataset[2*i+j][0].abs().numpy(), aspect=\"auto\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Audio import\n",
    "\n",
    "While audio files were taken as an example for the generic `Dataset` class, the `DatasetAudio` class provides additional features for sound import, notably specific import callbacks and temporal additional features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, torchaudio, pdb\n",
    "\n",
    "from vschaos.data import DatasetAudio, Normalize, SequencePick, ComposeAudioTransform\n",
    "from vschaos.data.data_transforms import Mono, STFT, Squeeze, Polar\n",
    "from vschaos.utils.dataloader import DataLoader\n",
    "\n",
    "data_prefix = \"dataset\"\n",
    "audioSet = DatasetAudio(data_prefix, drop_time=\"both\") # drop_time can be \"data\", \"meta\", or \"both\"\n",
    "audioSet.import_data(options={'resampleTo':22050}) \n",
    "# imported data corresponds to the raw signal\n",
    "magnitude_args = {'constrast':'log1p', 'normalize':{'mode':'minmax', 'scale':'unipolar'}}\n",
    "phase_args = {'unwrap':True, 'normalize':{'mode':'gaussian', 'scale':'bipolar'}}\n",
    "audioSet.transforms = ComposeAudioTransform([Mono(), Squeeze(0), STFT(2048),  Polar(mag_options=magnitude_args, phase_options=phase_args)])\n",
    "audioSet.scale_transforms(True)\n",
    "\n",
    "data, metadata = audioSet[0]\n",
    "print(\"magnitude : \", data[0].shape)\n",
    "print(\"phase : \", data[1].shape)\n",
    "print(\"time as data : \", data[2].shape)\n",
    "print(\"time as metadata : \", metadata['time'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy data generation\n",
    "\n",
    "`vsacids` also provides a toy dataset generation routine, grid sampling the parameters of audio generation units, defiined in the file `vschaos.data.toys.synthesis`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import vschaos.data.toys.synthesis as syn\n",
    "\n",
    "generator = syn.additive_generator\n",
    "parameters = {'n_partials':torch.arange(1,3),\n",
    "              'harmonic_decay': torch.Tensor([0.01, 1.0, 2.0]),\n",
    "              'f0':torch.linspace(10, 500, 5)}\n",
    "\n",
    "# generate the dataset!\n",
    "dataset, _ = syn.dataset_from_generator(1.0, 44100, generator, export=\"toy_additive_test\", **parameters)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ids = torch.randperm(len(dataset))[:12].tolist()\n",
    "fig, ax = plt.subplots(3, 4)\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        ax[i, j].plot(dataset[ids[3*i+j]][0][2000:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
