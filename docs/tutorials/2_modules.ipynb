{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULES\n",
    "\n",
    "## Multi-layer perceptrons \n",
    "\n",
    "The `vschaos.modules` package provides high-level methods implementing neural networks used in black-box variational inference. Most modules take into arguments two different dictionaries : one regarding the input properties, and one regarding the hidden properties. By example, the :py:class:`MLP` module allows to easily define multi-layered perceptrons (MLP) :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.modules import MLP\n",
    "import torch\n",
    "\n",
    "input_params = {'dim':200}\n",
    "hidden_params = {'nlayers':3, 'dim':[200, 100, 50], 'dropout':0.5, 'batch_norm':'batch'}\n",
    "module = MLP(input_params, hidden_params)\n",
    "print('input : ', input_params)\n",
    "print('hidden : ', hidden_params)\n",
    "print(module)\n",
    "\n",
    "x = torch.Tensor(64, 200)\n",
    "out = module(x)\n",
    "print(x.shape, '->', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vschaos.modules import MLP\n",
    "import torch\n",
    "\n",
    "# the parameters of each layer can be defined, provided that each arrays' length equals the number of layers\n",
    "input_params = {'dim':200}\n",
    "hidden_params = {'nlayers':3, 'dim':[200, 100, 50], 'dropout':[0.0, 0.3, 0.5], 'batch_norm':[None, None, 'batch']}\n",
    "module = MLP(input_params, hidden_params)\n",
    "print('input : ', input_params)\n",
    "print('hidden : ', hidden_params)\n",
    "print(module)\n",
    "\n",
    "x = torch.Tensor(64, 200)\n",
    "out = module(x)\n",
    "print(x.shape, '->', out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../..')\n",
    "from vschaos.modules import MLP\n",
    "import torch\n",
    "\n",
    "# The :class:`MLP` also allows multi-input and multi-output\n",
    "input_params = {'dim':200}\n",
    "hidden_params = [{'nlayers':3, 'dim':[200, 100, 50], 'dropout':[0.0, 0.3, 0.5], 'batch_norm':[None, None, 'batch']},\n",
    "                 {'nlayers':2, 'dim':[200, 100], 'dropout':[0.3, 0.5], 'batch_norm':[None, 'batch']}]\n",
    "module = MLP(input_params, hidden_params, linked=True) # if linked is true, the separate modules concatenate the inputs\n",
    "print('input : ', input_params)\n",
    "print('hidden : ', hidden_params)\n",
    "print(module)\n",
    "\n",
    "x = torch.Tensor(64, 200)\n",
    "out = module(x)\n",
    "print(x[0].shape, '-> ', out[0].shape, ' ; ', x[1].shape, ' -> ', out[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../..')\n",
    "from vschaos.modules import MLP\n",
    "from vschaos import distributions as dist\n",
    "import torch\n",
    "\n",
    "# input conditioning is parametrized in the hidden_params argument, where the label parameters are defined as dicts\n",
    "input_params = [{'dim':200}, {'dim':100}]\n",
    "class_params = {'dim':8, 'dist':dist.Categorical}\n",
    "style_params = {'dim':4, 'dist':dist.Categorical}\n",
    "hidden_params = {'dim':[200, 30], 'nlayers':2, 'linked':False, 'label_params':{'class':class_params, 'style':style_params}}\n",
    "module = MLP(input_params, hidden_params)\n",
    "x = [torch.randn(64, 200), torch.randn(64, 100)]\n",
    "y = {'class':torch.randint(0, 8, (64,)), 'style':torch.randint(0, 4, (64,))}\n",
    "print(module)\n",
    "\n",
    "out = module(x, y=y)\n",
    "print([x[0].shape, x[1].shape], \"->\", out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional modules\n",
    "\n",
    "Besides MLPs, `vschaos` also provides high level methods for convolutional modules, including flattening options to link a latent space to convolutional outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vschaos.modules import MLP\n",
    "from vschaos.modules import Convolutional, Deconvolutional\n",
    "\n",
    "# CONVs : convolutional and deconvolutional modules take extended parameters\n",
    "input_params = {'dim':2048, 'channels':16}\n",
    "class_params = {'dim':8, 'dist':dist.Categorical}\n",
    "style_params = {'dim':4, 'dist':dist.Categorical}\n",
    "hidden_params = {'kernel_size':[16, 8, 4], 'channels':[16, 8, 4], 'stride':[1,2,4], 'dilation':[2,2,4],\n",
    "                 'batch_norm_conv':['batch', 'batch', 'batch'], 'dropout_conv':[0.2, 0.4, 0.6],\n",
    "                 'label_params':{'class':class_params, 'style':style_params}, 'conditioning':'concat'}\n",
    "conv_module = Convolutional(input_params, hidden_params)\n",
    "deconv_module = Deconvolutional(input_params, hidden_params)\n",
    "print('conv : ', conv_module)\n",
    "print('deconv : ', deconv_module)\n",
    "\n",
    "x = torch.Tensor(64, 16, 1024)\n",
    "y = {'class':torch.randint(0, 8, (64,)), 'style':torch.randint(0, 4, (64,))}\n",
    "out = conv_module(x, y=y)\n",
    "out_deconv = deconv_module(x, y=y)\n",
    "print('conv', out.shape)\n",
    "print('deconv', out_deconv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ConvolutionalLatent` class embeds the output convolutional module into a flattened hidden representation of the input with an MLP, allowing to be then projected in a latent space. Inversely, `DeconvolutionalLatent` processes the latent code with an MLP, whose output is resized to be then processed by a `Deconvolution` module. These modules also allow multi-inputs, concatenating hidden representations. \n",
    "For `DeconvolutionLatent`, a target size can be given by the pout keyword, allowing to automatically retrieve the output size of the flattening module. **However**, remind that DeconvolutionalLatent does not perform the last convolution from hidden layers to pouts, as this operation is usually performed by a distribution module. See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vschaos import distributions as dist\n",
    "from vschaos.modules import ConvolutionalLatent, DeconvolutionalLatent\n",
    "\n",
    "input_params = [{'dim':2048, 'channels':16}, {'dim':512, 'channels':16}]\n",
    "class_params = {'dim':8, 'dist':dist.Categorical}\n",
    "style_params = {'dim':4, 'dist':dist.Categorical}\n",
    "hidden_params = {'dim':800, 'nlayers':2, 'kernel_size':[16, 8, 4], 'channels':[16, 8, 4], 'stride':[1,2,4], 'dilation':[2,2,4],\n",
    "                 'batch_norm_conv':['batch', 'batch', 'batch'], 'dropout_conv':[0.2, 0.4, 0.6],\n",
    "                 'label_params':{'class':class_params, 'style':style_params}, 'conditioning':'concat'}\n",
    "conv_module = ConvolutionalLatent(input_params, hidden_params)\n",
    "deconv_module = DeconvolutionalLatent({'dim':hidden_params['dim'], 'nlayers':1}, hidden_params, pouts=input_params)\n",
    "print('conv : ', conv_module)\n",
    "print('deconv : ', deconv_module)\n",
    "\n",
    "x = torch.Tensor(64, 16, 2048)\n",
    "x = [torch.Tensor(64, 16, 2048), torch.Tensor(64, 16, 512)]\n",
    "\n",
    "y = {'class':torch.randint(0, 8, (64,)), 'style':torch.randint(0, 4, (64,))}\n",
    "out = conv_module(x, y=y)\n",
    "print('conv', out.shape)\n",
    "\n",
    "out_deconv = deconv_module(out, y=y)\n",
    "print('deconv', out_deconv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `vschaos` library also defines a list of modules that directly encode the parameters of a given distribution, providing directly a `vschaos.Distribution` object. `vschaos.Distribution`, that overrides the native `torch.distribution` library, implements several distribution manipulation functions such as reshaping, squeezing, and defines several other distributions such as random processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vschaos.distributions as dist \n",
    "from vschaos.modules import get_module_from_density\n",
    "\n",
    "input_params = {'dim': 200}\n",
    "output_params = {'dim':32, 'dist':dist.Normal} #implemented so far : dist.Bernoulli, dist.Normal, dist.Categorical\n",
    "\n",
    "# the get_module_from_density returns the correct layer for a given distribution\n",
    "dist_module = get_module_from_density(output_params['dist'])\n",
    "module = dist_module(input_params, output_params)\n",
    "print(module)\n",
    "\n",
    "x = torch.Tensor(64, 200)\n",
    "out = module(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These distribution modules can also be defined using convolution modules, that is automatically done if the input dimensionality is greater than 1 or if the keyword `\"conv\"` is specified in the output parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../..')\n",
    "import vschaos.distributions as dist \n",
    "from vschaos.modules import get_module_from_density\n",
    "\n",
    "input_params = {'dim': 200, 'channels':[32, 32], 'kernel_size':[5, 3]}\n",
    "output_params = {'dim': 32, 'dist':dist.Bernoulli, 'conv':True}\n",
    "\n",
    "# the get_module_from_density returns the correct layer for a given distribution\n",
    "dist_module = get_module_from_density(output_params['dist'])\n",
    "module = dist_module(input_params, output_params)\n",
    "print(module)\n",
    "\n",
    "x = torch.Tensor(64, 32, 200).normal_()\n",
    "out = module(x)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders and decoders\n",
    "\n",
    "In variational auto-encoding modules, variational and generative distributions are defined as distributions whose parameters are defined as functions of respectively the input and the latent vector  $$q(\\boldsymbol{z|x}) \\sim \\mathcal{D}(\\boldsymbol{\\phi}(\\mathbf{x}))$$ \n",
    "$$p(\\boldsymbol{x|z}) \\sim \\mathcal{D}(\\boldsymbol{\\theta}(\\mathbf{z}))$$\n",
    "\n",
    "In the `vschaos` library, these modules are implemented using the `HiddenModule` class, that embeds a bottleneck module (MLP or Convolutional) and a distribution module. They can be additionally conditioned by external class information by specifying the parameters of the corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from vschaos import distributions as dist\n",
    "from vschaos.modules import HiddenModule, ConvolutionalLatent, DeconvolutionalLatent\n",
    "from vschaos.utils import apply_method\n",
    "\n",
    "# here we defined two different inputs\n",
    "input_params = [{'dim':1024, 'channels':2, 'dist':dist.Normal, 'conv':True}, {'dim':2048, 'channels': 2, 'dist':dist.Bernoulli, 'conv':True}]\n",
    "#Â the parameters of the conditioning label information\n",
    "class_params = {'dim':8, 'dist':dist.Categorical}\n",
    "style_params = {'dim':4, 'dist':dist.Categorical}\n",
    "# we define the parameters of the bottleneck module\n",
    "hidden_params = {'dim':800, 'nlayers':2, 'kernel_size':[16, 8, 4], 'channels':[16, 8, 4], 'stride':[1,2,4], 'dilation':[2,2,4], \n",
    "                 'batch_norm_conv':['batch', 'batch', 'batch'], 'dropout_conv':[0.2, 0.4, 0.6],\n",
    "                 'label_params':{'class':class_params, 'style':style_params}, 'conditioning':'concat',\n",
    "                 'class':ConvolutionalLatent}\n",
    "# and, finally, the latent parameters (can be split, as we do here in two different latent spaces)\n",
    "latent_params = [{'dim':8, 'dist':dist.Normal}, {'dim':4, 'dist':dist.Normal}]\n",
    "encoder = HiddenModule(input_params, phidden=hidden_params, pouts=latent_params)\n",
    "\n",
    "# forward!\n",
    "x = [torch.zeros(64, 2, 1024).normal_(), torch.zeros(64, 2, 2048).normal_()]\n",
    "y = {'class':torch.randint(0, 8, (64,)), 'style':torch.randint(0, 4, (64,))}\n",
    "out = encoder(x, y=y, return_hidden=True)\n",
    "\n",
    "print(out.keys())\n",
    "print('encoder out hidden', out['hidden'][0].shape)\n",
    "print('encoder out parameters : ', out['out_params'])\n",
    "\n",
    "# the apply_method allows to apply a method for each element of an array\n",
    "encoder_out = apply_method(out['out_params'], 'rsample');\n",
    "print('sampled output : ', encoder_out[0].shape, encoder_out[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the module has to mirror an encoder, it can be given to DeconvolutionalLatent\n",
    "#   to automatically fit the encoder's shape\n",
    "hidden_params = dict(hidden_params); hidden_params['class'] = DeconvolutionalLatent\n",
    "decoder = HiddenModule(latent_params, phidden=hidden_params, pouts=input_params, encoder=encoder.hidden_modules)\n",
    "# print(encoder, decoder)\n",
    "\n",
    "out = decoder(encoder_out, y=y)\n",
    "print('decoder out parameters : ', out['out_params'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
